{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python code used for project \"OpenStreetMap Data Wrangling with MongoDB\"\n",
    "\n",
    "For this project, I downloaded a compressed XML file from MapZen (www.mapzen.com/data/metro-extracts/), which provides weekly extracts of preselected metro areas in OpenStreetMap. The data represents approximately 2,500 square miles of OpenStreetMap data in and around the Milwaukee, Wisconsin metro area. OpenStreetMap is a contributor maintained map of the world. OpenStreetMap (OSM) users are encouraged to contribute local knowledge such as store opening hours, number of floors in an apartment building, whether or not a business has a drive thru, etc.\n",
    "After running validation checks on the data to ensure the XML fit the OSM data model (described here: http://wiki.openstreetmap.org/wiki/OSM_XML), Python cElementTree was used to iteratively parse the data for export to JSON and load into a local MongoDB instance.\n",
    "\n",
    "Map area: Milwaukee, Wisconsin https://mapzen.com/data/metro-extracts/#milwaukee-wisconsin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#tree based XML parsing: read all of the XML into memory, transform into a tree, work all the nodes on this tree\n",
    "#alternative to in-memory parsing: iterative parsing such as the'sax parser' \n",
    "#parse one tag at a time. each time you see a tag is an \"event\"\n",
    "#we will use cElementTree to iteratively parse our osm XML file\n",
    "import xml.etree.cElementTree as ET\n",
    "import pprint\n",
    "\n",
    "#next save the osm XML file input and targeted json output paths here\n",
    "#use codecs and json libraries later to write to a .json file\n",
    "filename = 'milwaukee_wisconsin.osm'\n",
    "file_out = 'milwaukee_wisconsin.json'\n",
    "import codecs\n",
    "import json\n",
    "\n",
    "#use pymongo for connecting to a local mongodb database called \"osm\"\n",
    "#this database is initially empty, but we will load our milwaukee osm data into a mongo collection called \"p3\" (as in \"project 3\")\n",
    "from pymongo import MongoClient\n",
    "client = MongoClient('localhost:27017')\n",
    "db = client.osm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's get a feel for the osm XML by taking a look at just the first 20 lines of the data file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "main loop 1, osm: {'timestamp': '2016-02-13T00:26:02Z', 'version': '0.6', 'generator': 'osmconvert 0.7T'}\n",
      "main loop 2, bounds: {'minlat': '42.656', 'maxlon': '-87.522', 'minlon': '-88.511', 'maxlat': '43.389'}\n",
      "main loop 3, node: uid 108601, user whammypower788\n",
      "main loop 4, node: uid 1751737, user Skybunny\n",
      "     tag: {'k': 'ref', 'v': '73B'}\n",
      "     tag: {'k': 'highway', 'v': 'motorway_junction'}\n",
      "main loop 5, node: uid 108601, user whammypower788\n",
      "main loop 6, node: uid 69864, user Ivan Komarov\n",
      "main loop 7, node: uid 69864, user Ivan Komarov\n",
      "main loop 8, node: uid 69864, user Ivan Komarov\n",
      "main loop 9, node: uid 69864, user Ivan Komarov\n",
      "main loop 10, node: uid 207745, user NE2\n",
      "     tag: {'k': 'ref', 'v': '83'}\n",
      "     tag: {'k': 'highway', 'v': 'motorway_junction'}\n",
      "main loop 11, node: uid 108601, user whammypower788\n",
      "main loop 12, node: uid 108601, user whammypower788\n",
      "main loop 13, node: uid 108601, user whammypower788\n",
      "main loop 14, node: uid 4732, user iandees\n",
      "main loop 15, node: uid 108601, user whammypower788\n",
      "main loop 16, node: uid 108601, user whammypower788\n",
      "main loop 17, node: uid 108601, user whammypower788\n",
      "main loop 18, node: uid 108601, user whammypower788\n",
      "main loop 19, node: uid 108601, user whammypower788\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "limit = 20\n",
    "\n",
    "for event,elem in ET.iterparse(filename, events=(\"start\",)):\n",
    "    counter += 1\n",
    "    if counter >= limit:\n",
    "        break\n",
    "    #parse iteratively. looking for specific things ('events') in the xml\n",
    "    #event is always \"end\" if you dont specify a tuple parm \"events=\"...\n",
    "    #remember, end tuples in python with a comma so not (\"start\"), its (\"start\",)\n",
    "    #elem is the <xml tag> (name is \"elem.tag\"). get attributes using elem.attrib\n",
    "    \n",
    "    main_loop_tagname = elem.tag\n",
    "    if main_loop_tagname in ['tag']:\n",
    "        counter -= 1\n",
    "        continue #iterparse (main loop) will parse over the tags we already processed cause they were nested under nodes and ways\n",
    "    \n",
    "    print_main_attrib = \": {}\".format(elem.attrib) #'' #elem.attrib\n",
    "    if main_loop_tagname <> 'node':\n",
    "        print_main_attrib = \": {}\".format(elem.attrib)\n",
    "    else:\n",
    "        print_main_attrib = \": {}\".format(elem.attrib)\n",
    "        print_main_attrib = \": uid {}, user {}\".format(elem.attrib['uid'],elem.attrib['user'])\n",
    "    print \"main loop {}, {}{}\".format(counter,main_loop_tagname,print_main_attrib)\n",
    "    if main_loop_tagname == 'node':\n",
    "        for tag in elem.iter():\n",
    "            if tag.tag == elem.tag:\n",
    "                #interesting that elem.iter() actually starts at the element node itself...\n",
    "                continue\n",
    "            #loop thru this parent node, to find only tags w name \"tag\" use elem.iter(\"tag\")\n",
    "            print \"     {}: {}\".format(tag.tag,tag.attrib)\n",
    "        elem.clear()\n",
    "        continue\n",
    "    elem.clear()\n",
    "    #ways are streets. for both node and ways, they follow with \"tag\" tags, with attribs for that way or node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, looping over the entire 166MB osm file, print out the total count of each different XML tag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bounds': 1,\n",
      " 'member': 7338,\n",
      " 'nd': 911537,\n",
      " 'node': 738460,\n",
      " 'osm': 1,\n",
      " 'relation': 657,\n",
      " 'tag': 468592,\n",
      " 'tax-yearg': 1,\n",
      " 'way': 83158}\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "for event,elem in ET.iterparse(filename, events=(\"start\",)):\n",
    "    main_loop_tagname = elem.tag\n",
    "    if main_loop_tagname in results:\n",
    "        results[main_loop_tagname] += 1\n",
    "    else:\n",
    "        results[main_loop_tagname] = 1\n",
    "pprint.pprint(results) #all tags, ignoring parent/child relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now know there are 738,460 nodes and 83,158 ways we will want to load as documents into MongoDB. Somewhere in the neighborhood of 468,592 tags will also be loaded as fields on our documents (tags nested under 'relations' will not be loaded). The data model for the osm XML is described here: https://wiki.openstreetmap.org/wiki/OSM_XML\n",
    "\n",
    "Now that we know the totals, let's try getting a feel for the XML's tag nesting structure so that we can confirm the data conforms to the data model documentation linked above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bounds.bounds': 1,\n",
      " 'member.member': 7338,\n",
      " 'nd.nd': 911537,\n",
      " 'node.node': 738460,\n",
      " 'node.tag': 48534,\n",
      " 'osm.bounds': 1,\n",
      " 'osm.node': 103,\n",
      " 'osm.osm': 1,\n",
      " 'osm.tag': 11,\n",
      " 'relation.member': 6657,\n",
      " 'relation.relation': 657,\n",
      " 'relation.tag': 4189,\n",
      " 'tag.tag': 468592,\n",
      " 'tax-yearg.tax-yearg': 1,\n",
      " 'way.nd': 875872,\n",
      " 'way.tag': 403732,\n",
      " 'way.tax-yearg': 1,\n",
      " 'way.way': 83158}\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "for event,elem in ET.iterparse(filename, events=(\"start\",)):\n",
    "    main_loop_tagname = elem.tag\n",
    "    #if main_loop_tagname in ['tag']:\n",
    "    #    continue #iterparse (main loop) will parse over the tags we already processed cause they were nested under nodes and ways\n",
    "    \n",
    "    if 1==1: #main_loop_tagname in ['node','way']:\n",
    "        for tag in elem.iter():\n",
    "            mini_loop_tagname = tag.tag\n",
    "            #if mini_loop_tagname == main_loop_tagname:\n",
    "            #    continue\n",
    "            #loop thru this parent node, to find only tags w name \"tag\" use elem.iter(\"tag\")\n",
    "            #print \"     {}: {}\".format(tag.tag,tag.attrib)\n",
    "            key_string = main_loop_tagname + \".\" + mini_loop_tagname\n",
    "            if key_string in results:\n",
    "                results[key_string] += 1\n",
    "            else:\n",
    "                results[key_string] = 1\n",
    "    #ways are streets. for both node and ways, they follow with \"tag\" tags, with attribs for that way or node.\n",
    "pprint.pprint(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**It seems that something is wrong with our XML parser.** First off, we already know that there are over 700,000 nodes in the file, but our first attempt at parsing the XML nesting structure found only 103 nodes nested under the root ('osm')! \n",
    "\n",
    "Next, we also know there are 468,593 \"tag\" tags. The OSM documentation states that \"tags\" are always nested under a parent node, way, or relation, yet our nesting-search parser is more than 12,000 tags short of the 468,593 tags that the document-total parser found:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "468593\n",
      "12091\n"
     ]
    }
   ],
   "source": [
    "#um... why when just looking at tags we see that there are 738,460 nodes and 468,593 \"tag\" tags...\n",
    "#but when i run my \"for tag in elem.iter()\" loop, it says the count of osm.node = 103, should osm.node be 738,460??\n",
    "#and the count of all the tags are ~12k short of the total tags??\n",
    "print 468593 \n",
    "print 468593 - 48534 - 4190 - 403778"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The answer, as described in the Project Summary document, is that the size of this XML file dictates we not iterate over nested (children) tags until reaching the \"end\" tag of a given element. That means we cannot know how many \"nodes\" are nested under the root \"osm\" element until we reach the `\"</osm>\"`. Similarly, we cannot know how many \"tag\" elements are nested under a node until we reach the `\"</node>\"` of that node. \n",
    "\n",
    "I wish I could simply change the \"events\" tuple parameter passed into our parser, but unfortunately we **must** have the parser examine the \"start\" elements because start elements such as `\"<node>\"` and `\"<way>\"` have attribute information that we could not access if we were to completely ignore the start elements.\n",
    "\n",
    "To accomodate all of this, I had to specify the parser to examine **both** start and end elements in the XML, pulling attribute data from start elements and only iterating over children nodes when at an end element. With this modification to the code, I could finally have the parser return an accurate summary of the XML and its nesting structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bounds': {'bounds': {'end': 1, 'start': 1}},\n",
      " 'member': {'member': {'end': 7338, 'start': 7338}},\n",
      " 'nd': {'nd': {'end': 911537, 'start': 911537}},\n",
      " 'node': {'node': {'end': 738460, 'start': 738460},\n",
      "          'tag': {'end': 48834, 'start': 48534}},\n",
      " 'osm': {'bounds': {'end': 1, 'start': 1},\n",
      "         'member': {'end': 7338, 'start': 0},\n",
      "         'nd': {'end': 911537, 'start': 0},\n",
      "         'node': {'end': 738460, 'start': 103},\n",
      "         'osm': {'end': 1, 'start': 1},\n",
      "         'relation': {'end': 657, 'start': 0},\n",
      "         'tag': {'end': 468592, 'start': 11},\n",
      "         'tax-yearg': {'end': 1, 'start': 0},\n",
      "         'way': {'end': 83158, 'start': 0}},\n",
      " 'relation': {'member': {'end': 7338, 'start': 6657},\n",
      "              'relation': {'end': 657, 'start': 657},\n",
      "              'tag': {'end': 4425, 'start': 4189}},\n",
      " 'tag': {'tag': {'end': 468592, 'start': 468592}},\n",
      " 'tax-yearg': {'tax-yearg': {'end': 1, 'start': 1}},\n",
      " 'way': {'nd': {'end': 911537, 'start': 875872},\n",
      "         'tag': {'end': 415333, 'start': 403732},\n",
      "         'tax-yearg': {'end': 1, 'start': 1},\n",
      "         'way': {'end': 83158, 'start': 83158}}}\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "for event,elem in ET.iterparse(filename, events=(\"start\",\"end\")):\n",
    "    main_loop_tagname = elem.tag\n",
    "    #if main_loop_tagname in ['tag']:\n",
    "    #    continue #iterparse (main loop) will parse over the tags we already processed cause they were nested under nodes and ways\n",
    "    \n",
    "    if 1==1: #main_loop_tagname in ['node','way']:\n",
    "        for tag in elem.iter():\n",
    "            mini_loop_tagname = tag.tag\n",
    "            #if mini_loop_tagname == main_loop_tagname:\n",
    "            #    continue\n",
    "            #loop thru this parent node, to find only tags w name \"tag\" use elem.iter(\"tag\")\n",
    "            #print \"     {}: {}\".format(tag.tag,tag.attrib)\n",
    "            key_string = \"{}.{}\".format(main_loop_tagname,mini_loop_tagname)\n",
    "            if main_loop_tagname in results:\n",
    "                if mini_loop_tagname in results[main_loop_tagname]:\n",
    "                    results[main_loop_tagname][mini_loop_tagname][event] += 1\n",
    "                else:\n",
    "                    results[main_loop_tagname][mini_loop_tagname] = {\"start\":0,\"end\":0}\n",
    "                    results[main_loop_tagname][mini_loop_tagname][event] = 1\n",
    "            else:\n",
    "                results[main_loop_tagname] = {}\n",
    "                results[main_loop_tagname][mini_loop_tagname] = {\"start\":0,\"end\":0}\n",
    "                results[main_loop_tagname][mini_loop_tagname][event] = 1\n",
    "    #ways are streets. for both node and ways, they follow with \"tag\" tags, with attribs for that way or node.\n",
    "pprint.pprint(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "468593\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#using the above, we can see the datamodel in our file conforms to the documentation provided in the wiki\n",
    "    #at https://wiki.openstreetmap.org/wiki/OSM_XML\n",
    "'''\n",
    "osm is root node\n",
    "    bounds (only appears 1 time)\n",
    "    node (738k)\n",
    "        tag (49k)\n",
    "    way (83k)\n",
    "        nd (911k)\n",
    "        tag (415k)\n",
    "    relation (657)\n",
    "        member (7k)\n",
    "        tag (4k)\n",
    "'''\n",
    "\n",
    "#and we can verify that we are fully capturing all \"tag\" children that can be found in the root \"osm\" node\n",
    "print 468593 #tags found under osm root in document-wide parser\n",
    "print 468593 - 48834 - 4425 - 415334 #subtract \"tag\" nested in node, relation, and way found by our nested-structure parser "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following are my raw notes written shortly after finally solving the mystery on why the iterparse() returned different counts when run document-wide and iterating through nested elements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ah ha! so we see our first issue with the data: (not counting elem.iter() starting at the element.self tag...)\n",
    "#the osm file is so big (103+ MB) that we cannot fully parse it using xml.etree.cElementTree.iterparse with only \"start\" events\n",
    "#this is a known issue with cElementTree's iterparse method (see: green text box at http://effbot.org/zone/element-iterparse.htm#usage)\n",
    "#full reference here: https://mail.python.org/pipermail/xml-sig/2005-January/010838.html\n",
    "#python docs on iterparse \"start\" method issue here: https://docs.python.org/2/library/xml.etree.elementtree.html\n",
    "#essentially, this means that you cant iterate over an elements children using a 'start' event. must use 'end' event to do so.\n",
    "#this is unfortunate for us because we MUST use start events to capture the attributes stored in the xml start tags\n",
    "#so we must write more complex code that iterparse's over both start AND end events:\n",
    "    #start events to retrieve the attributes stored in XML start tags of nodes/ways/etc\n",
    "    #and end events so we can element iterate (elem.iter()) over the child tags (\"tag\" and \"nd\") of our nodes/ways/etc\n",
    "#how big of an issue is this? for the milwaukee OSM xml file, the count of node tags using 'start' events was equal to 'end' events\n",
    "    #but the count of node's child \"tag\" jumped 300 and way's child nd jumped from 875,955 to 911,537 by waiting until an 'end' event to elem.iter()\n",
    "#data at the end of the file (like relation data) is improved the most when switching to only use end events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export data to JSON and Load into MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#this function will set up the dictionary we can use to evaluate the volume of various issues that might be present in the data\n",
    "def initialize_errors():\n",
    "    errors = {}\n",
    "    errors['num_key_problemchars'] = 0\n",
    "    errors['key_problemchars'] = {}\n",
    "    \n",
    "    errors['num_attrib_parse'] = 0\n",
    "    errors['attrib_parse'] = {}\n",
    "    \n",
    "    errors['num_badkey'] = 0\n",
    "    errors['badkey'] = {}\n",
    "    \n",
    "    errors['num_badvalue'] = 0\n",
    "    errors['badvalue'] = {}\n",
    "    \n",
    "    errors['num_addr_subkeys'] = 0\n",
    "    errors['addr_subkeys'] = {}\n",
    "    errors['num_gnis_subkeys'] = 0\n",
    "    errors['gnis_subkeys'] = {}\n",
    "    errors['num_tiger_subkeys'] = 0\n",
    "    errors['tiger_subkeys'] = {}\n",
    "    errors['num_seamark_subkeys'] = 0\n",
    "    errors['seamark_subkeys'] = {}\n",
    "    \n",
    "    errors['num_colonkeys'] = 0\n",
    "    errors['colonkeys'] = {}\n",
    "\n",
    "    errors['colon_key_tails'] = {}\n",
    "    errors['colon_value_tails'] = {}\n",
    "    \n",
    "    errors['num_colonvalues'] = 0\n",
    "    errors['colonvalues'] = {}\n",
    "    return errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this function will be used to parse the attributes stored in <node> and <way> tags \n",
    "    #(a.k.a. \"parent\" tags because the \"tag\" and \"nd\" tags are 'children' nested under these parent <node> and <way>)\n",
    "\n",
    "CREATED = ['version','changeset','timestamp','user','uid']\n",
    "\n",
    "def parse_parent_tag(tag_type,attrib,errors):\n",
    "    document = {}\n",
    "    document['created'] = {}\n",
    "    document['k_v_tag_count'] = 0 #initialize the count of children \"tags\" right here\n",
    "    lon = None\n",
    "    lat = None\n",
    "    \n",
    "    document['document_tag_type'] = tag_type\n",
    "    for k,val in attrib.iteritems():\n",
    "        if k in ['id','visible']:\n",
    "            document[k] = val\n",
    "            continue\n",
    "        elif k in CREATED:\n",
    "            document['created'][k] = val\n",
    "            continue\n",
    "        elif k == 'lon':\n",
    "            lon = float(val)\n",
    "        elif k == 'lat':\n",
    "            lat = float(val)\n",
    "        else:\n",
    "            errors['num_attrib_parse'] += 1\n",
    "            errors['attrib_parse'][attrib['id']] = {tag_type:attrib}\n",
    "            #print \"UNKNOWN ATTRIBUTE PARSE {} [{}] {},{}\".format(tag_type,attrib['id'],k,val)\n",
    "    if lat and lon:\n",
    "        #store latitude and longitude in a list for 2d geospatial indexing in mongo\n",
    "        document['pos'] = [lat,lon]\n",
    "    return document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#set up regular expressions to vet the strings that compose the keys and values for nested tags \n",
    "import re\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "valid = re.compile(r'^[a-zA-Z0-9_-]+$')\n",
    "#these last two regex are used in the course code but I have chosen to use the regex \"valid\" instead\n",
    "#lower = re.compile(r'^([a-z]|_)*$')\n",
    "#lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this function was originally used to remove certain characters from nested tag \"v\" values\n",
    "#it was later decided not to clean the nested tag values in this way but I leave the code here for future reference\n",
    "def format_value(value,errors):\n",
    "    if value.find(':')>0:\n",
    "        errors['num_colonvalues'] += 1\n",
    "        value_head = value[:value.find(':')]\n",
    "        if not (value_head in errors['colonvalues']):\n",
    "            errors['colonvalues'][value_head] = 1\n",
    "        else:\n",
    "            errors['colonvalues'][value_head] += 1\n",
    "        value = value.replace(':','-')\n",
    "    value = value.replace(' ','_')\n",
    "    value = value.replace(';','_')\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#this function will perform the transform and formatting of the nested tag keys and values\n",
    "    #much code has been added to log errors into an \"errors\" dictionary\n",
    "#nested tag keys starting with \"gnis:\", \"addr:\", \"tiger:\", and \"seamark:\" are added into document level dictionaries\n",
    "    #example: a value of \"Milwaukee\" with a key of \"gnis:county\" \n",
    "        #would be saved into the document under the \"gnis\" dictionary...\n",
    "        #'gnis':{'county':'Milwaukee'}\n",
    "    #these operations are also logged to the same 'errrors' dictionary (though they aren't literally \"errors\")\n",
    "#if a key other than gnis, addr, tiger, or seamark has a \":\" in it, save to the document level dictionary \"bad_keys\"\n",
    "    #these tag keys and values should be examined further in the future to best determine how to transform and incorporate into the wider document\n",
    "\n",
    "def add_tag_vals(document, key, value, counter ,errors):\n",
    "    #value = format_value(value,errors) #edit: do not need to remove special characters from the tag values\n",
    "    if problemchars.search(key):\n",
    "        errors['num_key_problemchars'] += 1\n",
    "        errors['key_problemchars'][document['id']] = {'key':key,'value':value}\n",
    "        \n",
    "    elif not valid.search(key.replace(':','')):\n",
    "        errors['num_badkey'] += 1\n",
    "        errors['badkey'][document['id']] = {'key':key,'value':value}\n",
    "    \n",
    "    elif key.find(':')>0:\n",
    "        key_head = key[:key.find(':')]\n",
    "        key_tail = key[key.find(':')+1:].replace(':','_')\n",
    "        \n",
    "        if key_head == 'gnis':\n",
    "            if not ('gnis' in document):\n",
    "                document['gnis'] = {}\n",
    "            #k=\"gnis:County\",v=\"Milwaukee\" will be saved into document['gnis']['County']= Milwaukee...\n",
    "            document['gnis'][key_tail] = value\n",
    "            document['k_v_tag_count'] += 1\n",
    "            errors['num_gnis_subkeys'] += 1\n",
    "            if not (key_tail in errors['gnis_subkeys']):\n",
    "                errors['gnis_subkeys'][key_tail] = 1\n",
    "            else:\n",
    "                errors['gnis_subkeys'][key_tail] += 1\n",
    "        elif key_head == 'addr':\n",
    "            if not ('addr' in document):\n",
    "                document['addr'] = {}\n",
    "            document['addr'][key_tail] = value\n",
    "            document['k_v_tag_count'] += 1\n",
    "            errors['num_addr_subkeys'] += 1\n",
    "            if not (key_tail in errors['addr_subkeys']):\n",
    "                errors['addr_subkeys'][key_tail] = 1\n",
    "            else:\n",
    "                errors['addr_subkeys'][key_tail] += 1\n",
    "        elif key_head == 'tiger':\n",
    "            if not ('tiger' in document):\n",
    "                document['tiger'] = {}\n",
    "            document['tiger'][key_tail] = value\n",
    "            document['k_v_tag_count'] += 1\n",
    "            errors['num_tiger_subkeys'] += 1\n",
    "            if not (key_tail in errors['tiger_subkeys']):\n",
    "                errors['tiger_subkeys'][key_tail] = 1\n",
    "            else:\n",
    "                errors['tiger_subkeys'][key_tail] += 1\n",
    "        elif key_head == 'seamark':\n",
    "            if not ('seamark' in document):\n",
    "                document['seamark'] = {}\n",
    "            document['seamark'][key_tail] = value\n",
    "            document['k_v_tag_count'] += 1\n",
    "            errors['num_seamark_subkeys'] += 1\n",
    "            if not (key_tail in errors['seamark_subkeys']):\n",
    "                errors['seamark_subkeys'][key_tail] = 1\n",
    "            else:\n",
    "                errors['seamark_subkeys'][key_tail] += 1\n",
    "        else:\n",
    "            errors['num_colonkeys'] += 1\n",
    "\n",
    "            if not (key_head in errors['colonkeys']):\n",
    "                errors['colonkeys'][key_head] = 1\n",
    "            else:\n",
    "                errors['colonkeys'][key_head] += 1\n",
    "\n",
    "            if not (key_tail in errors['colon_key_tails']):\n",
    "                errors['colon_key_tails'][key_tail] = {}\n",
    "                errors['colon_key_tails'][key_tail][key_head] = 1\n",
    "            elif not (key_head in errors['colon_key_tails'][key_tail]):\n",
    "                errors['colon_key_tails'][key_tail][key_head] = 1\n",
    "            else:\n",
    "                errors['colon_key_tails'][key_tail][key_head] += 1\n",
    "            \n",
    "            if not ('bad_keys' in document):\n",
    "                document['bad_keys'] = {}\n",
    "            document['bad_keys'][key.replace(':','--')] = value\n",
    "    else:\n",
    "        #print \"add to top level of results: {},{}\".format(k,v)\n",
    "        document[key] = value\n",
    "        document['k_v_tag_count'] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#finally, this is the code that will iterate over the osm XML\n",
    "    #this function will loop over the tags specified in \"targets\" (typically: nodes and ways)\n",
    "    #the function can load into the local mongo database and collection \"osm.p3\"\n",
    "    #the function can also save the transformed data into a .json file\n",
    "def export_osm(file_out,targets,errors,limit=0,to_mongo=None,to_file=None):\n",
    "    if to_mongo:\n",
    "        db.p3.drop()\n",
    "    with codecs.open(file_out, \"w\") as fo: \n",
    "        data = []\n",
    "        counter = 0\n",
    "        errors = initialize_errors()\n",
    "\n",
    "        for event,elem in ET.iterparse(filename, events=(\"start\",\"end\")):\n",
    "            main_loop_tagname = elem.tag\n",
    "            if main_loop_tagname in ['osm','bounds']:\n",
    "                #these are the header info from our xml data file\n",
    "                if event == 'start':\n",
    "                    print '{}: {}'.format(main_loop_tagname,elem.attrib)\n",
    "                continue\n",
    "            elif main_loop_tagname in ['tag','nd','member']:\n",
    "                #these are all \"children\" tags that will be parsed when dealing with the end event of their parent, \n",
    "                    #no need to parse here in the main loop\n",
    "                continue\n",
    "            elif not (main_loop_tagname in targets): #typically, we will deal with nodes and ways only\n",
    "                continue\n",
    "\n",
    "            elif event == \"start\":\n",
    "                #when the parser reaches a 'start' tag, the only thing we can retrieve is the attrib dict stored in the start tag.\n",
    "                #save the iteration over the children tags until we reach the 'end' event of the tag\n",
    "                document = {} #start new document (row in our db)\n",
    "                document = parse_parent_tag(main_loop_tagname,elem.attrib,errors)\n",
    "                continue\n",
    "\n",
    "            elif event == 'end' and main_loop_tagname in targets:\n",
    "                #now that we are at the \"end\" event of the top level tag, we can iterate thru its child tags\n",
    "                for tag in elem.iter(\"tag\"): \n",
    "                    #^specify the target child tag, or else elem.iter() will start at the parent elem itself!\n",
    "                    add_tag_vals(document, tag.attrib['k'], tag.attrib['v'] ,counter ,errors)\n",
    "                    \n",
    "                if main_loop_tagname == 'way':\n",
    "                    #for \"way\" tags, we also need to process the list of nodes that are linked to this \"way\"\n",
    "                    nd_refs = []\n",
    "                    for nd in elem.iter(\"nd\"):\n",
    "                        nd_refs.append(nd.attrib['ref'])\n",
    "                    if len(nd_refs) > 0:\n",
    "                        document[\"node_refs\"] = nd_refs\n",
    "                counter += 1\n",
    "                if to_file:\n",
    "                    fo.write(json.dumps(document)+\"\\n\")\n",
    "                if to_mongo:\n",
    "                    db.p3.insert_one(document)\n",
    "                elem.clear()\n",
    "                if limit > 0 and counter > limit:\n",
    "                    #for debugging, we can use the limit parameter to set a hardstop on the number of documents parsed\n",
    "                    break\n",
    "    return errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "osm: {'timestamp': '2016-02-13T00:26:02Z', 'version': '0.6', 'generator': 'osmconvert 0.7T'}\n",
      "bounds: {'minlat': '42.656', 'maxlon': '-87.522', 'minlon': '-88.511', 'maxlat': '43.389'}\n"
     ]
    }
   ],
   "source": [
    "errors = {}\n",
    "targets = ['node','way']\n",
    "errors = export_osm(file_out,targets,errors,to_mongo=True,to_file=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OSM Data Export Log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "4621\n",
      "7687\n",
      "14442\n",
      "225441\n",
      "104\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print errors['num_badvalue']\n",
    "print errors['num_key_problemchars']\n",
    "print errors['num_attrib_parse']\n",
    "print errors['num_badkey']\n",
    "print errors['num_colonkeys']\n",
    "print errors['num_gnis_subkeys']\n",
    "print errors['num_addr_subkeys']\n",
    "print errors['num_tiger_subkeys']\n",
    "print errors['num_seamark_subkeys']\n",
    "print errors['num_colonvalues']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ^From the above, we can see there were...\n",
    "* 7,687 nested tags saved into \"gnis\" dictionaries\n",
    "* 14,442 nested tags saved into \"address\" dictionaries\n",
    "* 225,441 nested tags saved into \"tiger\" dictionaries\n",
    "* 104 nested tags saved into \"seamark\" dictionaries\n",
    "\n",
    "\n",
    "* And 4,621 nested tags saved into the \"bad_keys\" dictionaries\n",
    "\n",
    "\n",
    "* There were also 4,263 nested tag *values* that contained \":\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is an exploration of the sub keys (example: \"city\" is the subkey for the raw key \"addr:city\") saved to the address, gnis, tiger, and seamark document level dictionaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "addr subkeys: 14442\n",
      "{'city': 2553, 'full': 32, 'country': 926, 'historic': 1, 'state': 2396, 'street': 3115, 'housename': 66, 'postcode': 2125, 'suite': 5, 'housenumber': 3147, 'unit': 74, 'interpolation': 2}\n",
      "\n",
      "gnis subkeys: 7687\n",
      "{'Class': 170, 'feature_type': 49, 'created': 1413, 'import_uuid': 214, 'edited': 102, 'county_name': 263, 'ST_alpha': 170, 'id': 171, 'County': 170, 'feature_id': 1686, 'county_id': 1366, 'state_id': 1364, 'reviewed': 209, 'County_num': 170, 'ST_num': 170}\n",
      "\n",
      "tiger subkeys: 225441\n",
      "{'cfcc': 31489,\n",
      " 'county': 31551,\n",
      " 'name_base': 27656,\n",
      " 'name_base_1': 1938,\n",
      " 'name_base_2': 215,\n",
      " 'name_base_3': 25,\n",
      " 'name_base_4': 2,\n",
      " 'name_direction_prefix': 11308,\n",
      " 'name_direction_prefix_1': 448,\n",
      " 'name_direction_prefix_2': 36,\n",
      " 'name_direction_prefix_3': 5,\n",
      " 'name_direction_suffix': 221,\n",
      " 'name_direction_suffix_1': 10,\n",
      " 'name_direction_suffix_2': 12,\n",
      " 'name_type': 25638,\n",
      " 'name_type_1': 1266,\n",
      " 'name_type_2': 91,\n",
      " 'name_type_3': 13,\n",
      " 'reviewed': 31052,\n",
      " 'separated': 2945,\n",
      " 'source': 3471,\n",
      " 'tlid': 3487,\n",
      " 'upload_uuid': 3471,\n",
      " 'zip_left': 23681,\n",
      " 'zip_left_1': 1207,\n",
      " 'zip_left_2': 376,\n",
      " 'zip_left_3': 131,\n",
      " 'zip_left_4': 58,\n",
      " 'zip_right': 22840,\n",
      " 'zip_right_1': 540,\n",
      " 'zip_right_2': 178,\n",
      " 'zip_right_3': 53,\n",
      " 'zip_right_4': 26,\n",
      " 'zip_right_5': 1}\n",
      "\n",
      "seamark subkeys: 104\n",
      "{'beacon_lateral_category': 9,\n",
      " 'beacon_lateral_colour': 5,\n",
      " 'beacon_lateral_colour_pattern': 1,\n",
      " 'beacon_lateral_shape': 9,\n",
      " 'beacon_lateral_system': 9,\n",
      " 'buoy_lateral_category': 1,\n",
      " 'buoy_lateral_colour': 1,\n",
      " 'buoy_lateral_shape': 1,\n",
      " 'buoy_lateral_system': 1,\n",
      " 'fog_signal_category': 2,\n",
      " 'light_character': 10,\n",
      " 'light_colour': 10,\n",
      " 'light_group': 1,\n",
      " 'light_height': 5,\n",
      " 'light_period': 9,\n",
      " 'light_range': 5,\n",
      " 'topmark_colour': 6,\n",
      " 'topmark_colour_pattern': 1,\n",
      " 'topmark_shape': 6,\n",
      " 'type': 12}\n"
     ]
    }
   ],
   "source": [
    "print \"addr subkeys: {}\".format(errors['num_addr_subkeys'])\n",
    "print errors['addr_subkeys']\n",
    "print \"\"\n",
    "print \"gnis subkeys: {}\".format(errors['num_gnis_subkeys'])\n",
    "print errors['gnis_subkeys']\n",
    "print \"\"\n",
    "print \"tiger subkeys: {}\".format(errors['num_tiger_subkeys'])\n",
    "pprint.pprint(errors['tiger_subkeys'])\n",
    "print \"\"\n",
    "print \"seamark subkeys: {}\".format(errors['num_seamark_subkeys'])\n",
    "pprint.pprint(errors['seamark_subkeys'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It should be noted that \"tiger:\" only appears on ways. \n",
    "\n",
    "For nodes, the two major \":\"-containing tag keys are \"addr:\" and \"gnis:\". The above shows that there is no overlap in the subkeys for these two types of keys. Based on this, I decided to add \"addr\" and \"gnis\" tag values as **separate** document level dictionaries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a breakdown of the keys for the 4,621 tags saved into the \"bad_keys\" document level dictionaries. The first p-printed cell shows the distribution of the bad_keys by [the text appearing before the \":\" in the raw key]. The second p-printed cell shows the distribution of the bad_keys by [subkeys (text after the \":\"), then broken down by pre-\":\" text]. Use the first cell to find prominent \"keys:\" to next incorporate into the Mongo database, and use the second cell to make sure you aren't silo-ing data in one document-level dictionary that might also be saved in a different document-level dictionary (see: \"lanes\", for example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'FIXME': 2,\n",
      " 'NHD': 429,\n",
      " 'abandoned': 1,\n",
      " 'access': 13,\n",
      " 'aerialway': 8,\n",
      " 'alt_name': 1,\n",
      " 'area': 2,\n",
      " 'bell': 7,\n",
      " 'boatyard': 1,\n",
      " 'bridge': 35,\n",
      " 'building': 1246,\n",
      " 'bus': 10,\n",
      " 'camera': 1,\n",
      " 'capacity': 11,\n",
      " 'census': 68,\n",
      " 'communication': 1,\n",
      " 'community_centre': 1,\n",
      " 'contact': 1386,\n",
      " 'crossing': 1,\n",
      " 'cycleway': 8,\n",
      " 'dance': 6,\n",
      " 'demolished': 3,\n",
      " 'description': 1,\n",
      " 'destination': 247,\n",
      " 'diet': 1,\n",
      " 'dimensions': 3,\n",
      " 'disused': 33,\n",
      " 'entrance': 22,\n",
      " 'fire_hydrant': 4,\n",
      " 'flag': 25,\n",
      " 'fuel': 10,\n",
      " 'generator': 17,\n",
      " 'health_facility': 4,\n",
      " 'healthcare': 4,\n",
      " 'heritage': 3,\n",
      " 'hgv': 96,\n",
      " 'hov': 27,\n",
      " 'internet_access': 1,\n",
      " 'is_in': 2,\n",
      " 'isced': 15,\n",
      " 'junction': 19,\n",
      " 'key': 1,\n",
      " 'lanes': 23,\n",
      " 'maxheight': 2,\n",
      " 'maxspeed': 12,\n",
      " 'motor_vehicle': 10,\n",
      " 'name': 192,\n",
      " 'note': 18,\n",
      " 'odbl': 6,\n",
      " 'parking': 2,\n",
      " 'payment': 17,\n",
      " 'phone': 1,\n",
      " 'piste': 10,\n",
      " 'plant': 10,\n",
      " 'population': 1,\n",
      " 'railway': 7,\n",
      " 'ramp': 9,\n",
      " 'recycling': 68,\n",
      " 'ref': 6,\n",
      " 'restaurant': 1,\n",
      " 'roof': 38,\n",
      " 'service': 8,\n",
      " 'social_facility': 9,\n",
      " 'source': 268,\n",
      " 'surveillance': 44,\n",
      " 'theater': 1,\n",
      " 'theatre': 1,\n",
      " 'toilets': 9,\n",
      " 'tourism': 1,\n",
      " 'tower': 35,\n",
      " 'traffic_signals': 2,\n",
      " 'turn': 17,\n",
      " 'wheelchair': 17}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(errors['colonkeys'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1800': {'name': 1},\n",
      " '1850': {'name': 1},\n",
      " '1860': {'name': 1},\n",
      " '1863': {'name': 1},\n",
      " '1880': {'name': 2},\n",
      " '1885-1886': {'name': 1},\n",
      " '1886-1914': {'name': 1},\n",
      " '1892': {'name': 1},\n",
      " '1892-1895': {'name': 1},\n",
      " '1895': {'name': 2},\n",
      " '1895-1900': {'name': 1},\n",
      " '1900': {'name': 1},\n",
      " '1901': {'name': 2},\n",
      " '1903': {'name': 1},\n",
      " '1907': {'name': 1},\n",
      " '1909': {'name': 1},\n",
      " '1911': {'name': 1},\n",
      " '1913': {'name': 1},\n",
      " '1914': {'name': 1},\n",
      " '1917-1927': {'name': 1},\n",
      " '1922': {'name': 1},\n",
      " '1928-1950': {'name': 1},\n",
      " '1931-1945': {'name': 1},\n",
      " '1934': {'name': 1},\n",
      " '1935': {'name': 1},\n",
      " '1945': {'name': 1},\n",
      " '1948': {'name': 1},\n",
      " '1949': {'name': 1},\n",
      " '1951': {'name': 1},\n",
      " '1955': {'name': 1},\n",
      " '1958': {'name': 1},\n",
      " '1960': {'name': 1},\n",
      " '1961-2014': {'name': 1},\n",
      " '1962': {'name': 1},\n",
      " '1963': {'name': 2},\n",
      " '1964': {'name': 1},\n",
      " '1965': {'name': 1},\n",
      " '1968': {'name': 1},\n",
      " '1969': {'name': 1},\n",
      " '1971': {'name': 1},\n",
      " '1972': {'name': 1},\n",
      " '1972-1995': {'name': 1},\n",
      " '1976': {'name': 1},\n",
      " '1980': {'name': 1},\n",
      " '1987': {'name': 1},\n",
      " '1989': {'name': 1},\n",
      " '1995': {'name': 1},\n",
      " '1996': {'name': 2},\n",
      " '2002': {'name': 1},\n",
      " '2003': {'name': 1},\n",
      " '2007': {'name': 1},\n",
      " '2008': {'name': 1},\n",
      " '2010': {'name': 2},\n",
      " 'ComID': {'NHD': 81},\n",
      " 'FCode': {'NHD': 81},\n",
      " 'FDate': {'NHD': 24},\n",
      " 'FTYPE': {'NHD': 24},\n",
      " 'FType': {'NHD': 57},\n",
      " 'RESOLUTION': {'NHD': 24},\n",
      " 'ReachCode': {'NHD': 81},\n",
      " 'access': {'source': 1},\n",
      " 'advisory': {'maxspeed': 12},\n",
      " 'aerosol_cans': {'recycling': 2},\n",
      " 'aeroway': {'disused': 1},\n",
      " 'aluminium': {'recycling': 2},\n",
      " 'amenity': {'demolished': 1, 'disused': 23},\n",
      " 'american_express': {'payment': 1},\n",
      " 'antifreeze': {'recycling': 1},\n",
      " 'architect': {'building': 257},\n",
      " 'architecture': {'building': 44},\n",
      " 'asphalt_roofing_shingles': {'recycling': 2},\n",
      " 'backward': {'lanes': 11},\n",
      " 'batteries': {'recycling': 1},\n",
      " 'beverage_cartons': {'recycling': 2},\n",
      " 'bicycle_chain_tool': {'service': 1},\n",
      " 'bicycle_diy': {'service': 1},\n",
      " 'bicycle_pump': {'service': 1},\n",
      " 'bicycle_rental': {'service': 1},\n",
      " 'bicycle_repair': {'service': 1},\n",
      " 'bicycle_retail': {'service': 1},\n",
      " 'bicycle_second_hand': {'service': 1},\n",
      " 'bitcoin': {'payment': 13},\n",
      " 'books': {'recycling': 2},\n",
      " 'building': {'demolished': 2, 'disused': 2},\n",
      " 'cans': {'recycling': 2},\n",
      " 'car_batteries': {'recycling': 2},\n",
      " 'cardboard': {'recycling': 2},\n",
      " 'cartons': {'recycling': 2},\n",
      " 'center_field': {'dimensions': 1},\n",
      " 'chipboard': {'recycling': 2},\n",
      " 'clli': {'key': 1},\n",
      " 'colour': {'building': 1, 'roof': 2},\n",
      " 'computers': {'recycling': 1},\n",
      " 'concrete': {'recycling': 1},\n",
      " 'conditional': {'access': 12},\n",
      " 'continent': {'is_in': 1},\n",
      " 'cooking_oil': {'recycling': 2},\n",
      " 'copy': {'service': 1},\n",
      " 'de': {'name': 1},\n",
      " 'description': {'wheelchair': 17},\n",
      " 'diesel': {'fuel': 6},\n",
      " 'difficulty': {'piste': 2},\n",
      " 'direction': {'traffic_signals': 2},\n",
      " 'disabled': {'capacity': 1},\n",
      " 'disposal': {'toilets': 6},\n",
      " 'e10': {'fuel': 1},\n",
      " 'electrical_items': {'recycling': 2},\n",
      " 'electronics': {'recycling': 1},\n",
      " 'email': {'contact': 180},\n",
      " 'email_1': {'contact': 1},\n",
      " 'empty': {'capacity': 8},\n",
      " 'en': {'alt_name': 1, 'description': 1, 'name': 2},\n",
      " 'en_1921-1961': {'name': 1},\n",
      " 'end_date': {'railway': 7},\n",
      " 'engine_oil': {'recycling': 2},\n",
      " 'facade_colour': {'building': 1},\n",
      " 'fax': {'contact': 117},\n",
      " 'fee': {'internet_access': 1},\n",
      " 'foil': {'recycling': 2},\n",
      " 'for': {'community_centre': 1, 'social_facility': 9},\n",
      " 'forward': {'lanes': 12},\n",
      " 'ft2': {'area': 1},\n",
      " 'furniture': {'recycling': 2},\n",
      " 'garden_waste': {'recycling': 2},\n",
      " 'genre': {'theater': 1, 'theatre': 1},\n",
      " 'glass': {'recycling': 1},\n",
      " 'glass_bottles': {'recycling': 2},\n",
      " 'green_waste': {'recycling': 1},\n",
      " 'grooming': {'piste': 1},\n",
      " 'hgv_national_network': {'source': 96},\n",
      " 'highway': {'abandoned': 1, 'disused': 1},\n",
      " 'historic': {'name': 122},\n",
      " 'historic_1': {'name': 2},\n",
      " 'hours': {'tourism': 1},\n",
      " 'housenumber': {'source': 1},\n",
      " 'lane_right': {'parking': 2},\n",
      " 'lanes': {'bus': 10,\n",
      "           'destination': 3,\n",
      "           'hov': 10,\n",
      "           'motor_vehicle': 10,\n",
      "           'note': 18,\n",
      "           'turn': 13},\n",
      " 'lanes_backward': {'turn': 3},\n",
      " 'lanes_forward': {'turn': 1},\n",
      " 'left': {'ref': 2},\n",
      " 'left_field': {'dimensions': 1},\n",
      " 'leisure': {'disused': 4},\n",
      " 'level': {'isced': 15},\n",
      " 'levels': {'building': 797, 'roof': 28},\n",
      " 'levels_underground': {'building': 23},\n",
      " 'light': {'crossing': 1},\n",
      " 'local': {'phone': 1},\n",
      " 'lt': {'name': 1},\n",
      " 'm2': {'area': 1},\n",
      " 'magazines': {'recycling': 2},\n",
      " 'mastercard': {'payment': 1},\n",
      " 'material': {'building': 15},\n",
      " 'maxspeed': {'source': 142},\n",
      " 'method': {'generator': 3},\n",
      " 'min_level': {'building': 4},\n",
      " 'minimum': {'hov': 17},\n",
      " 'mobile_phone': {'communication': 1},\n",
      " 'mobile_phones': {'recycling': 2},\n",
      " 'mount': {'camera': 1},\n",
      " 'movable': {'bridge': 23},\n",
      " 'myspace': {'contact': 1},\n",
      " 'name': {'FIXME': 1, 'source': 16},\n",
      " 'national_network': {'hgv': 96},\n",
      " 'newspaper': {'recycling': 2},\n",
      " 'noname': {'source': 2},\n",
      " 'note': {'odbl': 6},\n",
      " 'nrhp': {'ref': 3},\n",
      " 'number': {'building': 50},\n",
      " 'occupancy': {'aerialway': 8},\n",
      " 'octane_91': {'fuel': 1},\n",
      " 'octane_95': {'fuel': 1},\n",
      " 'octane_98': {'fuel': 1},\n",
      " 'operator': {'heritage': 3},\n",
      " 'output_cold_air': {'plant': 1},\n",
      " 'output_cold_water': {'plant': 1},\n",
      " 'output_compressed_air': {'plant': 1},\n",
      " 'output_electricity': {'plant': 2},\n",
      " 'output_hot_air': {'plant': 1},\n",
      " 'output_steam': {'plant': 2},\n",
      " 'paper': {'recycling': 1},\n",
      " 'paper_packaging': {'recycling': 1},\n",
      " 'parent': {'capacity': 1},\n",
      " 'part': {'building': 18},\n",
      " 'parts': {'contact': 1},\n",
      " 'phone': {'contact': 516},\n",
      " 'phone_1': {'contact': 21},\n",
      " 'phone_emergency': {'contact': 1},\n",
      " 'phone_onair': {'contact': 1},\n",
      " 'phone_tollfree': {'contact': 1},\n",
      " 'phone_tty': {'contact': 3},\n",
      " 'physical': {'maxheight': 2},\n",
      " 'plastic': {'recycling': 2},\n",
      " 'plastic_bags': {'recycling': 2},\n",
      " 'plastic_bottles': {'recycling': 2},\n",
      " 'population': {'census': 68},\n",
      " 'position': {'fire_hydrant': 1, 'source': 3, 'toilets': 1},\n",
      " 'printer_cartridges': {'recycling': 1},\n",
      " 'pub': {'disused': 1},\n",
      " 'ref': {'FIXME': 1, 'destination': 230, 'junction': 19},\n",
      " 'ref_lanes': {'destination': 2},\n",
      " 'ref_to': {'destination': 5},\n",
      " 'rfid': {'entrance': 22},\n",
      " 'right': {'cycleway': 8, 'ref': 1},\n",
      " 'right_field': {'dimensions': 1},\n",
      " 'roof_colour': {'building': 1},\n",
      " 'ru': {'name': 1},\n",
      " 'scrap_metal': {'recycling': 2},\n",
      " 'service': {'contact': 1},\n",
      " 'shape': {'roof': 8},\n",
      " 'sheet_metal': {'recycling': 1},\n",
      " 'shingles': {'recycling': 1},\n",
      " 'shoes': {'recycling': 2},\n",
      " 'shop': {'disused': 1},\n",
      " 'small_appliances': {'recycling': 2},\n",
      " 'source': {'generator': 12, 'plant': 2, 'population': 1},\n",
      " 'speciality': {'healthcare': 4},\n",
      " 'start_date': {'source': 1},\n",
      " 'state': {'is_in': 1},\n",
      " 'street': {'destination': 3},\n",
      " 'style': {'dance': 2},\n",
      " 'support': {'bell': 6, 'bridge': 12},\n",
      " 'teaching': {'dance': 4},\n",
      " 'to': {'destination': 4},\n",
      " 'tracer': {'source': 3},\n",
      " 'tty': {'contact': 1},\n",
      " 'tv_monitor': {'recycling': 1},\n",
      " 'type': {'bell': 1,\n",
      "          'boatyard': 1,\n",
      "          'building': 1,\n",
      "          'fire_hydrant': 3,\n",
      "          'flag': 25,\n",
      "          'generator': 2,\n",
      "          'health_facility': 4,\n",
      "          'piste': 7,\n",
      "          'restaurant': 1,\n",
      "          'surveillance': 44,\n",
      "          'tower': 35},\n",
      " 'tyres': {'recycling': 2},\n",
      " 'units': {'building': 19},\n",
      " 'use': {'building': 11},\n",
      " 'vegetarian': {'diet': 1},\n",
      " 'vehicle': {'access': 1},\n",
      " 'vertcoin': {'payment': 1},\n",
      " 'visa': {'payment': 1},\n",
      " 'waste': {'recycling': 1},\n",
      " 'way_id': {'NHD': 57},\n",
      " 'website': {'contact': 539},\n",
      " 'website_1': {'contact': 1},\n",
      " 'website_apartments': {'contact': 1},\n",
      " 'wheelchair': {'ramp': 9, 'toilets': 2},\n",
      " 'women': {'capacity': 1},\n",
      " 'year': {'building': 1},\n",
      " 'year_built': {'building': 3},\n",
      " 'zh': {'name': 3},\n",
      " 'zoomlevel': {'source': 3}}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(errors['colon_key_tails'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, I also did a check on the tag values that contained \":\". I initially had these \":\"-containing tag values logged because I was worried there could be messy data in the tag values, perhaps contributors used \":\" to nest information in tag values the same way they use it to nest information in tag keys?\n",
    "\n",
    "Thankfully, most of the tag values that contained \":\" were for valid reasons. The most prominent being web addresses (example \"http://www.google.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#most of the 790 values (v) [from nodes] that had colons in them were web addresses\n",
    "#pprint.pprint(errors['colonvalues'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
